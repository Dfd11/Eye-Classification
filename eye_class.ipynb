{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eye_class.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXN4q7_a0F4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import load_model\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from google.colab.patches import cv2_imshow\n",
        "from numpy import save,load\n",
        "import keras \n",
        "from keras.preprocessing import image\n",
        "from keras.engine import Layer\n",
        "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate\n",
        "from keras.layers import Activation, Dense, Dropout, Flatten\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "from keras import models\n",
        "from keras import layers \n",
        "from keras.applications import ResNet50\n",
        "import matplotlib.pyplot as plt\n",
        "carpet='Entrance26'\n",
        "\n",
        "start = keras.Input(shape=(32,32,3))\n",
        "Conv1 =layers.Conv2D(64,(3,3),padding='same',activation='relu')(start)\n",
        "Conv2 =layers.Conv2D(64,(3,3),padding='same',activation='relu')(Conv1)\n",
        "Pool1 =layers.MaxPooling2D(pool_size=(2,2))(Conv2)\n",
        "\n",
        "Conv3 =layers.Conv2D(128,(3,3),padding='same',activation='relu')(Pool1)\n",
        "Conv4 =layers.Conv2D(128,(3,3),padding='same',activation='relu')(Conv3)\n",
        "Pool2 =layers.MaxPooling2D(pool_size=(2,2))(Conv4)\n",
        "\n",
        "Conv5 =layers.Conv2D(256,(3,3),padding='same',activation='relu')(Pool2)\n",
        "Conv6 =layers.Conv2D(256,(3,3),padding='same',activation='relu')(Conv5)\n",
        "Pool3 =layers.MaxPooling2D(pool_size=(2,2))(Conv6)\n",
        "\n",
        "Flat =layers.Flatten()(Pool3)\n",
        "Den1 =layers.Dense(4*4*256,activation='relu')(Flat)\n",
        "Den2  =layers.Dense(256,activation='relu')(Den1)\n",
        "Den3  =layers.Dense(1,activation='sigmoid')(Den2)\n",
        "\n",
        "model=keras.Model(start,Den3)\n",
        "\n",
        "safe_acc=[]\n",
        "safe_val_acc=[]\n",
        "safe_loss=[]\n",
        "safe_val_loss=[]\n",
        "\n",
        "model.load_weights('/content/drive/My Drive/CNN2/Eyes/Trained Models/Entrance26/Checkpoints/Checkpoint_weight_49_0.06_0.98_0.00_0.95_.h5')\n",
        "X=[]\n",
        "\n",
        "for filename in os.listdir('../TryOut/'): #for each file in that directory\n",
        "    print(filename)\n",
        "    photo=img_to_array(load_img('../TryOut/'+filename))    \n",
        "    X.append(photo)\n",
        "\n",
        "cropped=[]\n",
        "sq=16\n",
        "detector=MTCNN()\n",
        "\n",
        "temp=[]\n",
        "for sample in range(len(X)):\n",
        "    print(sample)\n",
        "    temp_photo=np.array(X[sample])\n",
        "    temp_faces=detector.detect_faces(temp_photo)\n",
        "    faces=len(temp_faces)\n",
        "    for i in range(faces):\n",
        "      x=temp_faces[i]['box'][0]\n",
        "      y=temp_faces[i]['box'][1]\n",
        "      w=temp_faces[i]['box'][2]\n",
        "      h=temp_faces[i]['box'][3]\n",
        "      croppedFace=temp_photo[y:y+h,x:x+w,:]\n",
        "      croppedFace=cv2.resize(croppedFace,(100,100))\n",
        "      temp=detector.detect_faces(croppedFace)\n",
        "      if(len(temp)!=0):\n",
        "        x1,y1=temp[0]['keypoints']['left_eye']\n",
        "        croppedL=croppedFace[y1-sq:y1+sq,x1-sq:x1+sq,:]\n",
        "        x,y=temp[0]['keypoints']['right_eye']\n",
        "        croppedR=croppedFace[y-sq:y+sq,x-sq:x+sq,:]\n",
        "        croppedL=croppedL.reshape((1,32,32,3))\n",
        "        croppedR=croppedR.reshape((1,32,32,3))\n",
        "        if(model.predict(croppedL)==1):\n",
        "          if(model.predict(croppedR)==1):\n",
        "            print('Closed')\n",
        "          else:\n",
        "            print('Open')\n",
        "        else:\n",
        "          print('Open')\n",
        "        croppedFace=cv2.rectangle(croppedFace,(x-sq,y-sq),(x+sq,y+sq),(255,0,0),(1))\n",
        "        croppedFace=cv2.rectangle(croppedFace,(x1-sq,y1-sq),(x1+sq,y1+sq),(255,0,0),(1))\n",
        "        cv2_imshow(croppedFace)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}