{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SvL3YIhJjjS",
        "colab_type": "code",
        "outputId": "e3f97e8a-7fc3-464d-9c32-f2e73394a2d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "!pip3 install mtcnn\n",
        "from numpy import save,load\n",
        "import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.engine import Layer\n",
        "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate\n",
        "from keras.layers import Activation, Dense, Dropout, Flatten\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.core import RepeatVector, Permute\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "import cv2\n",
        "from matplotlib import pyplot\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mtcnn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/43/abee91792797c609c1bf30f1112117f7a87a713ebaa6ec5201d5555a73ef/mtcnn-0.1.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (2.3.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.18.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmpgJwesKDqv",
        "colab_type": "code",
        "outputId": "23f1173c-1cc3-484e-b72a-0b4940444874",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#SET UP DRIVE IN COLAB\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/My Drive/CNN2/Face'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/.shortcut-targets-by-id/1uu4MCOdjfOx0BLZ5kH2wt4bVozidgPTq/CNN2/Face\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3448GFDQrvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LOAD ALL FILES IN /FACES/DATA wich contain 100x100 images of faces with closed and open eyes \n",
        "closed_eye_x=[]\n",
        "photo=[]\n",
        "i=0\n",
        "\n",
        "\n",
        "for filename in os.listdir('./data/ClosedFace/'):\n",
        "    print(filename)\n",
        "    photo=img_to_array(load_img('./data/ClosedFace/'+filename))\n",
        "    closed_eye_x.append(photo)\n",
        "    #print(photo.shape)\n",
        "    #if(i==2):\n",
        "    #  break\n",
        "    i=i+1\n",
        "    print(i)\n",
        "\n",
        "closed_eye_x=np.array(closed_eye_x,dtype=float)\n",
        "save('./data/data_closed_face_x.npy',closed_eye_x) #saves the array as a binary for easier re-loading\n",
        "\n",
        "open_eye_x=[]\n",
        "photo=[]\n",
        "i=0\n",
        "for filename in os.listdir('./data/OpenFace/'):\n",
        "    print(filename)\n",
        "    photo=img_to_array(load_img('./data/OpenFace/'+filename))\n",
        "    \n",
        "    open_eye_x.append(photo)\n",
        "    #if(i==2):\n",
        "    #  break\n",
        "    i=i+1\n",
        "    print(i)\n",
        "\n",
        "photo=[]\n",
        "open_eye_x=np.array(open_eye_x,dtype=float)\n",
        "save('./data/data_open_face_x.npy',open_eye_x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzWVDnPxRJ6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "closed_eye_x=load('./data/data_closed_face_x.npy') #loads binary files if they exist\n",
        "open_eye_x=load('./data/data_open_face_x.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCvTkGX8WsRU",
        "colab_type": "code",
        "outputId": "aa0595d2-6b8e-4bb5-d65b-157310600db4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#CROP THE EYES FROM EACH IMAGE, POSITION OF EYES GIVEN BY Multi-Task Cascaded Convolutional Networks model or MTCNN()\n",
        "X=[]\n",
        "sq=16\n",
        "detector=MTCNN()\n",
        "temp=[]\n",
        "for sample in range(len(closed_eye_x)):\n",
        "    temp=detector.detect_faces(closed_eye_x[sample])\n",
        "    if(len(temp)!=0):\n",
        "      x,y=temp[0]['keypoints']['left_eye']\n",
        "      croppedL=closed_eye_x[sample,y-sq:y+sq,x-sq:x+sq,:]\n",
        "      x,y=temp[0]['keypoints']['right_eye']\n",
        "      croppedR=closed_eye_x[sample,y-sq:y+sq,x-sq:x+sq,:]\n",
        "      X.append(croppedL)\n",
        "      X.append(croppedR)\n",
        "X=np.array(X)\n",
        "print(X.shape) \n",
        "save('./data/data_closed_face_cropped_x.npy',X)\n",
        "\n",
        "X=[]\n",
        "\n",
        "temp=[]\n",
        "for sample in range(len(open_eye_x)):\n",
        "    temp=detector.detect_faces(open_eye_x[sample])\n",
        "    if(len(temp)!=0):\n",
        "      x,y=temp[0]['keypoints']['left_eye']\n",
        "      croppedL=open_eye_x[sample,y-sq:y+sq,x-sq:x+sq,:]\n",
        "      x,y=temp[0]['keypoints']['right_eye']\n",
        "      croppedR=open_eye_x[sample,y-sq:y+sq,x-sq:x+sq,:]\n",
        "      X.append(croppedL)\n",
        "      X.append(croppedR)\n",
        "X=np.array(X)\n",
        "print(X.shape)\n",
        "save('./data/data_open_face_cropped_x.npy',X)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2228, 32, 32, 3)\n",
            "(2454, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN8iVVe0S-7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "closed_eye_x_crop=load('./data/data_closed_face_cropped_x.npy') #loads binary files if they exist\n",
        "open_eye_x_crop=load('./data/data_open_face_cropped_x.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}